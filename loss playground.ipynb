{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import math\n",
    "from ssd_encoder_decoder.matching_utils import match_bipartite_greedy32\n",
    "from bounding_box_utils.bounding_box_utils_tf import tf_iou\n",
    "from bounding_box_utils.bounding_box_utils import convert_coordinates, iou_float\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "K.set_session(sess)\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeTimer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = \" '\"  + name + \"'\" if name else ''\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = timeit.default_timer()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.took = (timeit.default_timer() - self.start) * 1000.0\n",
    "        print('Code block' + self.name + ' took: ' + str(self.took) + ' ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load(\"outputs/predder.npy\")\n",
    "gt1 = gt[1]['predictions_1']\n",
    "gt2 = gt[1]['predictions_2']\n",
    "gt1_proj = gt[1]['predictions_1_to_2']\n",
    "gt2_proj = gt[1]['predictions_2_to_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.load(\"outputs/predictions_1_e0.npy\")\n",
    "pred_1_to_2 = np.load(\"outputs/predictions_1_to_2_e0.npy\")\n",
    "pred_2 = np.load(\"outputs/predictions_2_e0.npy\")\n",
    "pred_2_proj = np.load(\"outputs/predictions_2_to_1_e0.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_ratio = 3\n",
    "n_neg_min = 0\n",
    "alpha = 1\n",
    "\n",
    "def smooth_L1_loss(y_true, y_pred):\n",
    "    absolute_loss = tf.abs(y_true - y_pred)\n",
    "    square_loss = 0.5 * (y_true - y_pred)**2\n",
    "    l1_loss = tf.where(tf.less(absolute_loss, 1.0), square_loss, absolute_loss - 0.5)\n",
    "    return tf.reduce_sum(l1_loss, axis=-1)\n",
    "\n",
    "def log_loss(y_true, y_pred):\n",
    "\n",
    "    y_pred = tf.maximum(y_pred, 1e-15)\n",
    "    # Compute the log loss\n",
    "    log_loss = -tf.reduce_sum(y_true * tf.log(y_pred), axis=-1)\n",
    "    return log_loss\n",
    "\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "\n",
    "    def gt_rem(pred, gt):\n",
    "        with CodeTimer('gt_rem'):\n",
    "        # predval = tf.shape(pred)\n",
    "        # gtval = tf.shape(gt)\n",
    "            val = tf.subtract(tf.shape(pred)[1],tf.shape(gt)[1])\n",
    "            gt = tf.slice(gt, [0, 0, 0], [1, tf.shape(pred)[0], 18],name=\"rem_slice\")\n",
    "        return gt\n",
    "\n",
    "    def gt_add(pred, gt):\n",
    "        with CodeTimer('gt_add'):\n",
    "            a = tf.shape(pred)[1]\n",
    "            b = tf.shape(gt)[1]\n",
    "\n",
    "            val = tf.subtract(tf.shape(pred),tf.shape(gt))\n",
    "            val = tf.cast(val[1], tf.int32)\n",
    "            ext = tf.slice(gt, [0, 0, 0], [1, 1, 18], name=\"add_slice\")\n",
    "            multiply = [1,val,1]\n",
    "            ext = tf.tile(ext, multiply)\n",
    "            gt = K.concatenate([ext,gt], axis=1)\n",
    "        return gt\n",
    "\n",
    "    def equalalready(gt, pred): return pred\n",
    "\n",
    "    def make_equal(pred, gt):\n",
    "        equal_tensor = tf.cond(tf.shape(pred)[1] < tf.shape(gt)[1], lambda: gt_rem(pred, gt), lambda: gt_add(pred, gt), name=\"make_equal_cond\")\n",
    "        return equal_tensor\n",
    "\n",
    "\n",
    "    def matcher(y_true_1,y_pred_1,y_true_2,y_pred_2, bsz):\n",
    "        pred = 0\n",
    "        gt = 0\n",
    "\n",
    "        for i in range(bsz):\n",
    "            print(\"i: \",i)\n",
    "            with CodeTimer('filtering'):\n",
    "                filterer = tf.where(tf.not_equal(y_true_1[i,:,-4],99))\n",
    "                filterer_2 = tf.where(tf.not_equal(y_true_2[i,:,-4],99))\n",
    "                \n",
    "                y_true_new = tf.gather_nd(y_true_1[i,:,:],filterer)            \n",
    "                y_true_new = tf.expand_dims(y_true_new, 0)\n",
    "                y_true_2_new = tf.gather_nd(y_true_2[i,:,:],filterer_2)\n",
    "                y_true_2_new = tf.expand_dims(y_true_2_new, 0)\n",
    "                \n",
    "                set1 = tf.cast(y_true_new[:,:,-4],dtype=tf.int32)\n",
    "                set2 = tf.cast(y_true_2_new[:,:,-4],dtype=tf.int32)\n",
    "                \n",
    "                id_pick = tf.sets.set_intersection(set1[None,:], set2[None, :])\n",
    "                id_pick = tf.cast(id_pick.values[0],dtype=tf.float32)\n",
    "                \n",
    "                filterer = tf.where(tf.equal(y_true_1[i,:,-4],id_pick))\n",
    "                filterer_2 = tf.where(tf.equal(y_true_2[i,:,-4],id_pick))\n",
    "                \n",
    "                y_true_new = tf.gather_nd(y_true_1[i,:,:],filterer) \n",
    "                y_true_new = tf.expand_dims(y_true_new, 0)\n",
    "                \n",
    "                y_true_2_new = tf.gather_nd(y_true_2[i,:,:],filterer_2)\n",
    "                y_true_2_new = tf.expand_dims(y_true_2_new, 0)\n",
    "                y_pred_1_new = y_pred_1[i,:,-16:-12]\n",
    "                \n",
    "            with CodeTimer('iou_out'):   \n",
    "#                 iou_out = tf.py_func(iou_float, [y_pred_1_new,y_true_new[0,:,-16:-12]], tf.float32, name=\"iou_out\")\n",
    "                iou_out = tf_iou(y_pred_1_new,y_true_new[0,:,-16:-12])\n",
    "    \n",
    "                print(K.eval(iou_out).shape)\n",
    "            with CodeTimer('bipartite_matches'):\n",
    "                bipartite_matches = tf.py_func(match_bipartite_greedy32, [iou_out], tf.int32, name=\"bipartite_matches\")\n",
    "                print(K.eval(bipartite_matches).shape)\n",
    "#             print(\"bipartite_matches \",K.eval(bipartite_matches).shape)\n",
    "#             print(\"y_pred_2[i,:,:] \",K.eval(y_pred_2[i,:,:]).shape)\n",
    "\n",
    "            with CodeTimer('out'):\n",
    "        \n",
    "                out = tf.gather(y_pred_2[i,:,:], [bipartite_matches], axis=0, name=\"out\")\n",
    "                print(K.eval(out).shape)\n",
    "            with CodeTimer('box_comparer'):\n",
    "                \n",
    "                box_comparer = tf.reduce_all(tf.equal(tf.shape(out)[1], tf.shape(y_true_2_new)[1]), name=\"box_comparer\")\n",
    "                print(K.eval(box_comparer).shape)\n",
    "            with CodeTimer('y_true_2_equal'):\n",
    "                y_true_2_equal = tf.cond(box_comparer, lambda: equalalready(out, y_true_2_new), lambda: make_equal(out, y_true_2_new), name=\"y_true_cond\")\n",
    "                print(K.eval(y_true_2_equal).shape)\n",
    "            with CodeTimer('concatentation'):\n",
    "\n",
    "                if i != 0:\n",
    "                    pred = K.concatenate([pred,out], axis=-1)\n",
    "                    gt = K.concatenate([gt,y_true_2_equal], axis=0)\n",
    "                else:\n",
    "                    pred = out\n",
    "                    gt = y_true_2_equal    \n",
    "        return pred, gt\n",
    "\n",
    "        \n",
    "    y_true_1 = y_true[:,:,:18]\n",
    "    y_pred_1 = y_pred[:,:,:18]\n",
    "    y_true_2 = y_true[:,:,18:]\n",
    "    y_pred_2 = y_pred[:,:,18:]\n",
    "\n",
    "    with CodeTimer('matcher'):\n",
    "        y_pred_out, y_true_out = matcher(y_true_1,y_pred_1,y_true_2,y_pred_2,1)\n",
    "        print(\"y_pred: \",K.eval(y_pred_out).shape)\n",
    "        print(\"y_true: \",K.eval(y_true_out).shape)\n",
    "    \n",
    "#     y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "#     y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    \n",
    "    with CodeTimer('box'):\n",
    "\n",
    "        batch_size = tf.shape(y_pred_out)[0]\n",
    "        n_boxes = tf.shape(y_true_out)[1] \n",
    "\n",
    "    with CodeTimer('classification_loss'):\n",
    "        classification_loss = tf.to_float(log_loss(y_true_out[:,:,:-16], y_pred_out[:,:,:-16])) # Output shape: (batch_size, n_boxes)\n",
    "    with CodeTimer('localization_loss'):\n",
    "        localization_loss = tf.to_float(smooth_L1_loss(y_true_out[:,:,-16:-12], y_pred_out[:,:,-16:-12])) # Output shape: (batch_size, n_boxes)\n",
    "    with CodeTimer('negatives'):\n",
    "        negatives = y_true_out[:,:,0] # Tensor of shape (batch_size, n_boxes)\n",
    "        positives = tf.to_float(tf.reduce_max(y_true_out[:,:,1:-16], axis=-1)) # Tensor of shape (batch_size, n_boxes)\n",
    "        n_positive = tf.reduce_sum(positives)\n",
    "    with CodeTimer('pos_class_loss'):\n",
    "        pos_class_loss = tf.reduce_sum(classification_loss * positives, axis=-1) # Tensor of shape (batch_size,)\n",
    "\n",
    "    with CodeTimer('neg_class_loss_all'):\n",
    "\n",
    "        neg_class_loss_all = classification_loss * negatives # Tensor of shape (batch_size, n_boxes)\n",
    "        n_neg_losses = tf.count_nonzero(neg_class_loss_all, dtype=tf.int32) # The number of non-zero loss entries in `neg_class_loss_all`\n",
    "        n_negative_keep = tf.minimum(tf.maximum(neg_pos_ratio * tf.to_int32(n_positive), n_neg_min), n_neg_losses)\n",
    "\n",
    "    def f1():\n",
    "        return tf.zeros([batch_size])\n",
    "    def f2():\n",
    "\n",
    "        neg_class_loss_all_1D = tf.reshape(neg_class_loss_all, [-1]) # Tensor of shape (batch_size * n_boxes,)\n",
    "        values, indices = tf.nn.top_k(neg_class_loss_all_1D,\n",
    "                                      k=n_negative_keep,\n",
    "                                      sorted=False) # We don't need them sorted.\n",
    "\n",
    "        negatives_keep = tf.scatter_nd(indices=tf.expand_dims(indices, axis=1),\n",
    "                                       updates=tf.ones_like(indices, dtype=tf.int32),\n",
    "                                       shape=tf.shape(neg_class_loss_all_1D)) # Tensor of shape (batch_size * n_boxes,)\n",
    "        negatives_keep = tf.to_float(tf.reshape(negatives_keep, [batch_size, n_boxes])) # Tensor of shape (batch_size, n_boxes)\n",
    "        # ...and use it to keep only those boxes and mask all other classification losses\n",
    "        neg_class_loss = tf.reduce_sum(classification_loss * negatives_keep, axis=-1) # Tensor of shape (batch_size,)\n",
    "        return neg_class_loss\n",
    "    \n",
    "    with CodeTimer('neg_class_loss_all'):\n",
    "        neg_class_loss = tf.cond(tf.equal(n_neg_losses, tf.constant(0)), f1, f2)\n",
    "\n",
    "        class_loss = pos_class_loss + neg_class_loss # Tensor of shape (batch_size,)\n",
    "\n",
    "        loc_loss = tf.reduce_sum(localization_loss * positives, axis=-1) # Tensor of shape (batch_size,)\n",
    "\n",
    "    # 4: Compute the total loss.\n",
    "    with CodeTimer('total_loss'):\n",
    "        total_loss = (class_loss + alpha * loc_loss) / tf.maximum(1.0, n_positive) # In case `n_positive == 0`\n",
    "        total_loss = total_loss * tf.to_float(batch_size)\n",
    "        total_loss.set_shape((None,))\n",
    "        print(K.eval(total_loss))\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 17292, 36)\n",
      "i:  0\n",
      "Code block 'filtering' took: 60.20039296709001 ms\n",
      "(17292, 4)\n",
      "Code block 'iou_out' took: 336.7081810720265 ms\n",
      "(17292,)\n",
      "Code block 'bipartite_matches' took: 21166.918084025383 ms\n",
      "(1, 17292, 18)\n",
      "Code block 'out' took: 20915.782656986266 ms\n",
      "()\n",
      "Code block 'box_comparer' took: 20904.535137000494 ms\n",
      "Code block 'gt_rem' took: 22.09624508395791 ms\n",
      "Code block 'gt_add' took: 137.30286492500454 ms\n",
      "(1, 17292, 18)\n",
      "Code block 'y_true_2_equal' took: 21047.589571913704 ms\n",
      "Code block 'concatentation' took: 0.007123919203877449 ms\n",
      "y_pred:  (1, 17292, 18)\n",
      "y_true:  (1, 17292, 18)\n",
      "Code block 'matcher' took: 125875.17393392045 ms\n",
      "Code block 'box' took: 12.275652959942818 ms\n",
      "Code block 'classification_loss' took: 11.934897978790104 ms\n",
      "Code block 'localization_loss' took: 14.568821992725134 ms\n",
      "Code block 'negatives' took: 9.315431001596153 ms\n",
      "Code block 'pos_class_loss' took: 2.085180953145027 ms\n",
      "Code block 'neg_class_loss_all' took: 9.473062003962696 ms\n",
      "Code block 'neg_class_loss_all' took: 24.4610010413453 ms\n",
      "[10.273645]\n",
      "Code block 'total_loss' took: 21070.704942103475 ms\n",
      "loss: [10.273645]\n"
     ]
    }
   ],
   "source": [
    "print(gt1_proj.shape)\n",
    "gt1_proj = tf.convert_to_tensor(gt1_proj,dtype=np.float32)\n",
    "pred_1_to_2 = tf.convert_to_tensor(pred_1_to_2,dtype=np.float32)\n",
    "loss = compute_loss(gt1_proj,pred_1_to_2)\n",
    "print(\"loss:\",K.eval(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
