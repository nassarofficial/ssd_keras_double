{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import math\n",
    "from ssd_encoder_decoder.matching_utils import match_bipartite_greedy, match_multi\n",
    "from bounding_box_utils.bounding_box_utils import iou, convert_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "K.set_session(sess)\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load(\"outputs/predder.npy\")\n",
    "gt1 = gt[1]['predictions_1']\n",
    "gt2 = gt[1]['predictions_2']\n",
    "gt1_proj = gt[1]['predictions_1_to_2']\n",
    "gt2_proj = gt[1]['predictions_2_to_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.load(\"outputs/predictions_1_e0.npy\")\n",
    "pred_1_to_2 = np.load(\"outputs/predictions_1_to_2_e0.npy\")\n",
    "pred_2 = np.load(\"outputs/predictions_2_e0.npy\")\n",
    "pred_2_proj = np.load(\"outputs/predictions_2_to_1_e0.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_ratio = 3\n",
    "n_neg_min = 0\n",
    "alpha = 1\n",
    "\n",
    "def smooth_L1_loss(y_true, y_pred):\n",
    "    absolute_loss = tf.abs(y_true - y_pred)\n",
    "    square_loss = 0.5 * (y_true - y_pred)**2\n",
    "    l1_loss = tf.where(tf.less(absolute_loss, 1.0), square_loss, absolute_loss - 0.5)\n",
    "    return tf.reduce_sum(l1_loss, axis=-1)\n",
    "\n",
    "def log_loss(y_true, y_pred):\n",
    "\n",
    "    y_pred = tf.maximum(y_pred, 1e-15)\n",
    "    # Compute the log loss\n",
    "    log_loss = -tf.reduce_sum(y_true * tf.log(y_pred), axis=-1)\n",
    "    return log_loss\n",
    "\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "\n",
    "    def gt_rem(pred, gt):\n",
    "        # predval = tf.shape(pred)\n",
    "        # gtval = tf.shape(gt)\n",
    "        val = tf.subtract(tf.shape(pred)[1],tf.shape(gt)[1])\n",
    "        gt = tf.slice(gt, [0, 0, 0], [1, tf.shape(pred)[0], 18],name=\"rem_slice\")\n",
    "        return gt\n",
    "\n",
    "    def gt_add(pred, gt):\n",
    "        a = tf.shape(pred)[1]\n",
    "        b = tf.shape(gt)[1]\n",
    "\n",
    "        val = tf.shape(pred)-tf.shape(gt)\n",
    "        val = tf.cast(val[1], tf.int32)\n",
    "        ext = tf.slice(gt, [0, 0, 0], [1, 1, 18], name=\"add_slice\")\n",
    "        multiply = [1,val,1]\n",
    "        ext = tf.tile(ext, multiply)\n",
    "        gt = K.concatenate([ext,gt], axis=1)\n",
    "        return gt\n",
    "\n",
    "    def equalalready(gt, pred): return pred\n",
    "\n",
    "    def make_equal(pred, gt):\n",
    "        equal_tensor = tf.cond(tf.shape(pred)[1] < tf.shape(gt)[1], lambda: gt_rem(pred, gt), lambda: gt_add(pred, gt), name=\"make_equal_cond\")\n",
    "        return equal_tensor\n",
    "\n",
    "\n",
    "    def matcher(y_true_1,y_pred_1,y_true_2,y_pred_2, bsz):\n",
    "        pred = 0\n",
    "        gt = 0\n",
    "\n",
    "        for i in range(bsz):\n",
    "            \n",
    "            filterer = tf.where(tf.not_equal(y_true_1[i,:,-4],99))\n",
    "            filterer_2 = tf.where(tf.not_equal(y_true_2[i,:,-4],99))\n",
    "\n",
    "            y_true_new = tf.gather_nd(y_true_1[i,:,:],filterer)            \n",
    "            y_true_new = tf.expand_dims(y_true_new, 0)\n",
    "            \n",
    "            y_true_2_new = tf.gather_nd(y_true_2[i,:,:],filterer_2)\n",
    "            y_true_2_new = tf.expand_dims(y_true_2_new, 0)\n",
    "\n",
    "            set1 = tf.cast(y_true_new[i,:,-4],dtype=tf.int32)\n",
    "            set2 = tf.cast(y_true_2_new[i,:,-4],dtype=tf.int32)\n",
    "            print(\"----: \",K.eval(set1))\n",
    "            print(\"----: \",K.eval(set2))\n",
    "\n",
    "            id_pick = tf.sets.set_intersection(set1[None,:], set2[None, :])\n",
    "            print(\"----: \",K.eval(id_pick.values[0]))\n",
    "            id_pick = tf.cast(id_pick.values[0],dtype=tf.float64)\n",
    "                        \n",
    "            filterer = tf.where(tf.equal(y_true_1[i,:,-4],id_pick))\n",
    "            filterer_2 = tf.where(tf.equal(y_true_2[i,:,-4],id_pick))\n",
    "\n",
    "            y_true_new = tf.gather_nd(y_true_1[i,:,:],filterer)            \n",
    "            y_true_new = tf.expand_dims(y_true_new, 0)\n",
    "            \n",
    "            y_true_2_new = tf.gather_nd(y_true_2[i,:,:],filterer_2)\n",
    "            y_true_2_new = tf.expand_dims(y_true_2_new, 0)\n",
    "            \n",
    "            iou_out = tf.py_func(iou, [y_pred_1[i,:,-16:-12],tf.convert_to_tensor(y_true_new[i,:,-16:-12])], tf.float64, name=\"iou_out\")\n",
    "            bipartite_matches = tf.py_func(match_bipartite_greedy, [iou_out], tf.int64, name=\"bipartite_matches\")\n",
    "            out = tf.gather(y_pred_2[i,:,:], [bipartite_matches], axis=0, name=\"out\")\n",
    "            \n",
    "            box_comparer = tf.reduce_all(tf.equal(tf.shape(out)[1], tf.shape(y_true_2_new)[1]), name=\"box_comparer\")\n",
    "\n",
    "\n",
    "            y_true_2_equal = tf.cond(box_comparer, lambda: equalalready(out, y_true_2_new), lambda: make_equal(out, y_true_2_new), name=\"y_true_cond\")\n",
    "\n",
    "            if i != 0:\n",
    "                pred = K.concatenate([pred,out], axis=-1)\n",
    "                gt = K.concatenate([gt,y_true_2_equal], axis=0)\n",
    "            else:\n",
    "                pred = out\n",
    "                gt = y_true_2_equal    \n",
    "        return pred, gt\n",
    "\n",
    "        \n",
    "    y_true_1 = y_true[:,:,:18]\n",
    "    y_pred_1 = y_pred[:,:,:18]\n",
    "    y_true_2 = y_true[:,:,18:]\n",
    "    y_pred_2 = y_pred[:,:,18:]\n",
    "\n",
    "    y_pred, y_true = matcher(y_true_1,y_pred_1,y_true_2,y_pred_2,4)\n",
    "                \n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "\n",
    "    y_pred1 = y_pred\n",
    "    t_true1 = y_true\n",
    "\n",
    "    batch_size = tf.shape(y_pred1)[0]\n",
    "    n_boxes = tf.shape(t_true1)[1] \n",
    "\n",
    "    classification_loss = tf.to_float(log_loss(t_true1[:,:,:-16], y_pred1[:,:,:-16])) # Output shape: (batch_size, n_boxes)\n",
    "    localization_loss = tf.to_float(smooth_L1_loss(t_true1[:,:,-16:-12], y_pred1[:,:,-16:-12])) # Output shape: (batch_size, n_boxes)\n",
    "\n",
    "    negatives = t_true1[:,:,0] # Tensor of shape (batch_size, n_boxes)\n",
    "    positives = tf.to_float(tf.reduce_max(t_true1[:,:,1:-16], axis=-1)) # Tensor of shape (batch_size, n_boxes)\n",
    "    n_positive = tf.reduce_sum(positives)\n",
    "\n",
    "    pos_class_loss = tf.reduce_sum(classification_loss * positives, axis=-1) # Tensor of shape (batch_size,)\n",
    "\n",
    "\n",
    "    neg_class_loss_all = classification_loss * negatives # Tensor of shape (batch_size, n_boxes)\n",
    "    n_neg_losses = tf.count_nonzero(neg_class_loss_all, dtype=tf.int32) # The number of non-zero loss entries in `neg_class_loss_all`\n",
    "    n_negative_keep = tf.minimum(tf.maximum(neg_pos_ratio * tf.to_int32(n_positive), n_neg_min), n_neg_losses)\n",
    "\n",
    "    def f1():\n",
    "        return tf.zeros([batch_size])\n",
    "    def f2():\n",
    "\n",
    "        neg_class_loss_all_1D = tf.reshape(neg_class_loss_all, [-1]) # Tensor of shape (batch_size * n_boxes,)\n",
    "        values, indices = tf.nn.top_k(neg_class_loss_all_1D,\n",
    "                                      k=n_negative_keep,\n",
    "                                      sorted=False) # We don't need them sorted.\n",
    "\n",
    "        negatives_keep = tf.scatter_nd(indices=tf.expand_dims(indices, axis=1),\n",
    "                                       updates=tf.ones_like(indices, dtype=tf.int32),\n",
    "                                       shape=tf.shape(neg_class_loss_all_1D)) # Tensor of shape (batch_size * n_boxes,)\n",
    "        negatives_keep = tf.to_float(tf.reshape(negatives_keep, [batch_size, n_boxes])) # Tensor of shape (batch_size, n_boxes)\n",
    "        # ...and use it to keep only those boxes and mask all other classification losses\n",
    "        neg_class_loss = tf.reduce_sum(classification_loss * negatives_keep, axis=-1) # Tensor of shape (batch_size,)\n",
    "        return neg_class_loss\n",
    "\n",
    "    neg_class_loss = tf.cond(tf.equal(n_neg_losses, tf.constant(0)), f1, f2)\n",
    "\n",
    "    class_loss = pos_class_loss + neg_class_loss # Tensor of shape (batch_size,)\n",
    "\n",
    "    loc_loss = tf.reduce_sum(localization_loss * positives, axis=-1) # Tensor of shape (batch_size,)\n",
    "\n",
    "    # 4: Compute the total loss.\n",
    "\n",
    "    total_loss = (class_loss + alpha * loc_loss) / tf.maximum(1.0, n_positive) # In case `n_positive == 0`\n",
    "    total_loss = total_loss * tf.to_float(batch_size)\n",
    "    total_loss.set_shape((None,))\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt1_proj = tf.convert_to_tensor(gt1_proj)\n",
    "pred_1_to_2 = tf.convert_to_tensor(pred_1_to_2)\n",
    "loss = compute_loss(gt1_proj,pred_1_to_2)\n",
    "print(\"loss:\",K.eval(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 17292, 36)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt1_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fa0882ec48cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt1_proj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "t = np.where(gt1_proj[2,:,-4]!=99) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105222., 105222., 105222., 105222., 105222.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt1_proj[2,t,-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [[1,3],[1,2],[1,4],[5,3],[3,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['23'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['23'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
