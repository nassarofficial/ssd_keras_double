{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import math\n",
    "from ssd_encoder_decoder.matching_utils import match_bipartite_greedy, match_multi\n",
    "from bounding_box_utils.bounding_box_utils import iou, convert_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "K.set_session(sess)\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load(\"outputs/predder.npy\")\n",
    "gt1 = gt[1]['predictions_1']\n",
    "gt2 = gt[1]['predictions_2']\n",
    "gt1_proj = gt[1]['predictions_1_to_2']\n",
    "gt2_proj = gt[1]['predictions_2_to_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.load(\"outputs/predictions_1_e0.npy\")\n",
    "pred_1_to_2 = np.load(\"outputs/predictions_1_to_2_e0.npy\")\n",
    "pred_2 = np.load(\"outputs/predictions_2_e0.npy\")\n",
    "pred_2_proj = np.load(\"outputs/predictions_2_to_1_e0.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_ratio = 3\n",
    "n_neg_min = 0\n",
    "alpha = 1\n",
    "\n",
    "def smooth_L1_loss(y_true, y_pred):\n",
    "    absolute_loss = tf.abs(y_true - y_pred)\n",
    "    square_loss = 0.5 * (y_true - y_pred)**2\n",
    "    l1_loss = tf.where(tf.less(absolute_loss, 1.0), square_loss, absolute_loss - 0.5)\n",
    "    return tf.reduce_sum(l1_loss, axis=-1)\n",
    "\n",
    "def log_loss(y_true, y_pred):\n",
    "\n",
    "    y_pred = tf.maximum(y_pred, 1e-15)\n",
    "    # Compute the log loss\n",
    "    log_loss = -tf.reduce_sum(y_true * tf.log(y_pred), axis=-1)\n",
    "    return log_loss\n",
    "\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "    def gt_rem(pred, gt):\n",
    "        # predval = tf.shape(pred)\n",
    "        # gtval = tf.shape(gt)\n",
    "        val = tf.subtract(tf.shape(pred)[1],tf.shape(gt)[1])\n",
    "        gt = tf.slice(gt, [0, 0, 0], [1, tf.shape(pred)[0], 18],name=\"rem_slice\")\n",
    "        return gt\n",
    "\n",
    "    def gt_add(pred, gt):\n",
    "        a = tf.shape(pred)[1]\n",
    "        b = tf.shape(gt)[1]\n",
    "        \n",
    "        val = tf.shape(pred)-tf.shape(gt)\n",
    "        print(\"val: \", val)\n",
    "        print(\"vals: \", K.eval(val))\n",
    "        val = tf.cast(val[1], tf.int32)\n",
    "        ext = tf.slice(gt, [0, 0, 0], [1, 1, 18], name=\"add_slice\")\n",
    "\n",
    "        multiply = tf.constant([1,val,1])\n",
    "        ext = tf.tile(ext, multiply)\n",
    "        gt = K.concatenate([ext,gt], axis=1)\n",
    "        return gt\n",
    "\n",
    "    def equalalready(gt, pred): return pred\n",
    "\n",
    "    def make_equal(pred, gt):\n",
    "\n",
    "#         equal_tensor = tf.cond(tf.less(tf.shape(pred)[1],tf.shape(gt)[1]), lambda: gt_rem(pred, gt), lambda: gt_add(pred, gt), name=\"make_equal_cond\")\n",
    "        equal_tensor = gt_add(pred, gt)\n",
    "        return equal_tensor\n",
    "\n",
    "    def matcher(y_true_1,y_pred_1,y_true_2,y_pred_2, bsz):\n",
    "        pred = 0\n",
    "        gt = 0\n",
    "\n",
    "#         for i in range(bsz):\n",
    "        i = 0\n",
    "        filterer = tf.where(tf.not_equal(y_true_1[i,:,-4],99))\n",
    "        filterer_2 = tf.where(tf.not_equal(y_true_2[i,:,-4],99))\n",
    "\n",
    "        y_true_new = tf.gather_nd(y_true_1[i,:,:],filterer)            \n",
    "        y_true_new = tf.expand_dims(y_true_new, 0)\n",
    "\n",
    "        y_true_2_new = tf.gather_nd(y_true_2[i,:,:],filterer_2)\n",
    "        y_true_2_new = tf.expand_dims(y_true_2_new, 0)\n",
    "\n",
    "        set1 = tf.cast(y_true_new[i,:,-4],dtype=tf.int32)\n",
    "        set2 = tf.cast(y_true_2_new[i,:,-4],dtype=tf.int32)\n",
    "\n",
    "        id_pick = tf.sets.set_intersection(set1[None,:], set2[None, :])\n",
    "        id_pick = tf.cast(id_pick.values[0],dtype=tf.float64)\n",
    "\n",
    "        filterer = tf.where(tf.equal(y_true_1[i,:,-4],id_pick))\n",
    "        filterer_2 = tf.where(tf.equal(y_true_2[i,:,-4],id_pick))\n",
    "\n",
    "        y_true_new = tf.gather_nd(y_true_1[i,:,:],filterer)            \n",
    "        y_true_new = tf.expand_dims(y_true_new, 0)\n",
    "\n",
    "        y_true_2_new = tf.gather_nd(y_true_2[i,:,:],filterer_2)\n",
    "        y_true_2_new = tf.expand_dims(y_true_2_new, 0)\n",
    "\n",
    "#             print(\"y_pred_1:\", y_pred_1[i,:,-16:-12].shape)\n",
    "#             print(\"y_true_new:\", K.eval(y_true_new[i,:,-16:-12]).shape)\n",
    "#             print(\"--------------------------------------------------\")\n",
    "\n",
    "        iou_out = tf.py_func(iou, [y_pred_1[i,:,-16:-12],tf.convert_to_tensor(y_true_new[i,:,-16:-12])], tf.float64, name=\"iou_out\")\n",
    "        bipartite_matches = tf.py_func(match_bipartite_greedy, [iou_out], tf.int64, name=\"bipartite_matches\")\n",
    "        out = tf.gather(y_pred_2[i,:,:], [bipartite_matches], axis=0, name=\"out\")\n",
    "\n",
    "#             print(\"iou_out:\", K.eval(iou_out).shape)\n",
    "#             print(\"bipartite_matches:\", K.eval(bipartite_matches).shape)\n",
    "#             print(\"out:\", K.eval(out).shape)\n",
    "#             print(\"--------------------------------------------------\")\n",
    "\n",
    "#             print(\"tf.shape(out)[1]:\", K.eval(tf.shape(out)[1]))\n",
    "#             print(\"tf.shape(y_true_2_new)[1]:\", K.eval(tf.shape(y_true_2_new)[1]))\n",
    "\n",
    "        box_comparer = tf.reduce_all(tf.equal(tf.shape(out)[1], tf.shape(y_true_2_new)[1]), name=\"box_comparer\")\n",
    "#         y_true_2_equal = tf.cond(box_comparer, lambda: equalalready(out, y_true_2_new), lambda: make_equal(out, y_true_2_new), name=\"y_true_cond\")\n",
    "        y_true_2_equal =make_equal(out, y_true_2_new)\n",
    "        if i != 0:\n",
    "            pred = K.concatenate([pred,out], axis=-1)\n",
    "            gt = K.concatenate([gt,y_true_2_equal], axis=0)\n",
    "        else:\n",
    "            pred = out\n",
    "            gt = y_true_2_equal    \n",
    "        return pred, gt\n",
    "\n",
    "        \n",
    "    y_true_1 = y_true[:,:,:18]\n",
    "    y_pred_1 = y_pred[:,:,:18]\n",
    "    y_true_2 = y_true[:,:,18:]\n",
    "    y_pred_2 = y_pred[:,:,18:]\n",
    "\n",
    "    y_pred, y_true = matcher(y_true_1,y_pred_1,y_true_2,y_pred_2,1)\n",
    "                \n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "\n",
    "    y_pred1 = y_pred\n",
    "    t_true1 = y_true\n",
    "\n",
    "    batch_size = tf.shape(y_pred1)[0]\n",
    "    n_boxes = tf.shape(t_true1)[1] \n",
    "\n",
    "    classification_loss = tf.to_float(log_loss(t_true1[:,:,:-16], y_pred1[:,:,:-16])) # Output shape: (batch_size, n_boxes)\n",
    "    localization_loss = tf.to_float(smooth_L1_loss(t_true1[:,:,-16:-12], y_pred1[:,:,-16:-12])) # Output shape: (batch_size, n_boxes)\n",
    "\n",
    "    negatives = t_true1[:,:,0] # Tensor of shape (batch_size, n_boxes)\n",
    "    positives = tf.to_float(tf.reduce_max(t_true1[:,:,1:-16], axis=-1)) # Tensor of shape (batch_size, n_boxes)\n",
    "    n_positive = tf.reduce_sum(positives)\n",
    "\n",
    "    pos_class_loss = tf.reduce_sum(classification_loss * positives, axis=-1) # Tensor of shape (batch_size,)\n",
    "\n",
    "\n",
    "    neg_class_loss_all = classification_loss * negatives # Tensor of shape (batch_size, n_boxes)\n",
    "    n_neg_losses = tf.count_nonzero(neg_class_loss_all, dtype=tf.int32) # The number of non-zero loss entries in `neg_class_loss_all`\n",
    "    n_negative_keep = tf.minimum(tf.maximum(neg_pos_ratio * tf.to_int32(n_positive), n_neg_min), n_neg_losses)\n",
    "\n",
    "    def f1():\n",
    "        return tf.zeros([batch_size])\n",
    "    def f2():\n",
    "\n",
    "        neg_class_loss_all_1D = tf.reshape(neg_class_loss_all, [-1]) # Tensor of shape (batch_size * n_boxes,)\n",
    "        values, indices = tf.nn.top_k(neg_class_loss_all_1D,\n",
    "                                      k=n_negative_keep,\n",
    "                                      sorted=False) # We don't need them sorted.\n",
    "\n",
    "        negatives_keep = tf.scatter_nd(indices=tf.expand_dims(indices, axis=1),\n",
    "                                       updates=tf.ones_like(indices, dtype=tf.int32),\n",
    "                                       shape=tf.shape(neg_class_loss_all_1D)) # Tensor of shape (batch_size * n_boxes,)\n",
    "        negatives_keep = tf.to_float(tf.reshape(negatives_keep, [batch_size, n_boxes])) # Tensor of shape (batch_size, n_boxes)\n",
    "        # ...and use it to keep only those boxes and mask all other classification losses\n",
    "        neg_class_loss = tf.reduce_sum(classification_loss * negatives_keep, axis=-1) # Tensor of shape (batch_size,)\n",
    "        return neg_class_loss\n",
    "\n",
    "    neg_class_loss = tf.cond(tf.equal(n_neg_losses, tf.constant(0)), f1, f2)\n",
    "\n",
    "    class_loss = pos_class_loss + neg_class_loss # Tensor of shape (batch_size,)\n",
    "\n",
    "    loc_loss = tf.reduce_sum(localization_loss * positives, axis=-1) # Tensor of shape (batch_size,)\n",
    "\n",
    "    # 4: Compute the total loss.\n",
    "\n",
    "    total_loss = (class_loss + alpha * loc_loss) / tf.maximum(1.0, n_positive) # In case `n_positive == 0`\n",
    "    total_loss = total_loss * tf.to_float(batch_size)\n",
    "    total_loss.set_shape((None,))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:  Tensor(\"sub:0\", shape=(3,), dtype=int32)\n",
      "vals:  [    0 17284     0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "List of Tensors when single Tensor expected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9d580bc67272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgt1_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt1_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_1_to_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_1_to_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt1_proj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_1_to_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiltered_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparent_ops\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a3db2f995435>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0my_pred_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a3db2f995435>\u001b[0m in \u001b[0;36mmatcher\u001b[0;34m(y_true_1, y_pred_1, y_true_2, y_pred_2, bsz)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mbox_comparer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_2_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"box_comparer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m#         y_true_2_equal = tf.cond(box_comparer, lambda: equalalready(out, y_true_2_new), lambda: make_equal(out, y_true_2_new), name=\"y_true_cond\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0my_true_2_equal\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmake_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_2_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a3db2f995435>\u001b[0m in \u001b[0;36mmake_equal\u001b[0;34m(pred, gt)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#         equal_tensor = tf.cond(tf.less(tf.shape(pred)[1],tf.shape(gt)[1]), lambda: gt_rem(pred, gt), lambda: gt_add(pred, gt), name=\"make_equal_cond\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mequal_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mequal_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a3db2f995435>\u001b[0m in \u001b[0;36mgt_add\u001b[0;34m(pred, gt)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"add_slice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmultiply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/tf3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    381\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmismatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"List of Tensors when single Tensor expected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "\u001b[0;31mTypeError\u001b[0m: List of Tensors when single Tensor expected"
     ]
    }
   ],
   "source": [
    "gt1_proj = tf.convert_to_tensor(gt1_proj)\n",
    "pred_1_to_2 = tf.convert_to_tensor(pred_1_to_2)\n",
    "loss = compute_loss(gt1_proj,pred_1_to_2)\n",
    "graph = tf.get_default_graph()\n",
    "filtered_ops = [op for op in parent_ops if graph.is_fetchable(op)]\n",
    "\n",
    "print(\"loss:\",K.eval(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
